{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamVinestock/NLP/blob/main/NLP_Part_of_speech_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zB2BpE6DhW"
      },
      "source": [
        "# Part-of-speech (POS) tagging\n",
        "\n",
        "This notebook is about training and evaluating a POS tagger with some real data. The dataset is available through the Universal Dependencies (https://universaldependencies.org/) (UD) project. To get to know the project, please visit https://universaldependencies.org/introduction.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8iWKz8IfKi5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee53d65-6ee2-481f-9a3e-5efcdb8caa13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for conllutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --q conllutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iRm7zcfq56HF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "import nltk\n",
        "from nltk.tag import tnt\n",
        "\n",
        "import operator\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "import conllutils\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH-Xvqip6Teu"
      },
      "source": [
        "## Part 1 - Dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTv6rMt0oIw9"
      },
      "source": [
        "For each package we set the random seed to 42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PtM4HY2LoYDn"
      },
      "outputs": [],
      "source": [
        "# Set the random seed for Python\n",
        "random.seed(42)\n",
        "\n",
        "# Set the random seed for numpy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the random seed for pandas\n",
        "# If no random state is passed in pandas, system will inherit np random seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuvbl0hooXXx"
      },
      "source": [
        "You can download the dataset files directly from the UD website, but it will let you only download all the languages in one compressed file. In this assignment you will be working with th GUM dataset, which you can download directly from:\n",
        "https://github.com/UniversalDependencies/UD_English-GUM.\n",
        "Please download it to your colab machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsZsyTVC6Sw0",
        "outputId": "04e2554b-328e-41b7-ed35-6e41eab44ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UD_English-GUM'...\n",
            "remote: Enumerating objects: 5045, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 5045 (delta 48), reused 12 (delta 6), pack-reused 4973\u001b[K\n",
            "Receiving objects: 100% (5045/5045), 43.88 MiB | 19.79 MiB/s, done.\n",
            "Resolving deltas: 100% (4682/4682), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_English-GUM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZGOtoteWHz"
      },
      "source": [
        "We will use the (train/dev/test) files:\n",
        "\n",
        "\n",
        "```\n",
        "UD_English-GUM/en_gum-ud-train.conllu\n",
        "UD_English-GUM/en_gum-ud-dev.conllu\n",
        "UD_English-GUM/en_gum-ud-test.conllu\n",
        "```\n",
        "\n",
        "\n",
        "They are all formatted in the conllu format. You may read about it [here](https://universaldependencies.org/format.html). There is a utility library **conllutils**, which can help you read the data into the memory. It has already been installed and imported above.\n",
        "\n",
        "We will write code that reads the three datasets into memory. We can choose the data structure ourselves. As you can see, every word is represented by a line, with columns representing specific features.   \n",
        "We are only interested in the first and fourth columns, corresponding to the word and its POS tag:\n",
        "- `FORM: The Word`\n",
        "- `UPOS: Universal part-of-speech tag`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v7A0-DjWg2JW"
      },
      "outputs": [],
      "source": [
        "#train_data,test_data = None, None\n",
        "\n",
        "train_data_conll = conllutils.read_conllu(\"/content/UD_English-GUM/en_gum-ud-train.conllu\")\n",
        "dev_data_conll = conllutils.read_conllu(\"/content/UD_English-GUM/en_gum-ud-dev.conllu\")\n",
        "test_data_conll = conllutils.read_conllu(\"/content/UD_English-GUM/en_gum-ud-test.conllu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "riq7adOsIvUR"
      },
      "outputs": [],
      "source": [
        "train_data = np.array([\n",
        "    [(word.get('form'), word.get('upos')) for word in sentence]\n",
        "    for sentence in train_data_conll\n",
        "    ], dtype=object)\n",
        "\n",
        "test_data = np.array([\n",
        "    [(word.get('form'), word.get('upos')) for word in sentence]\n",
        "    for sentence in test_data_conll\n",
        "    ], dtype=object)\n",
        "\n",
        "dev_data = np.array([\n",
        "    [(word.get('form'), word.get('upos')) for word in sentence]\n",
        "    for sentence in dev_data_conll\n",
        "    ], dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0Z9BMNM7EP3"
      },
      "source": [
        "## Part 2 - Simpler Tagger\n",
        "\n",
        "Here we will write a class **simple_tagger**, with methods `train` and `evaluate`.\n",
        "\n",
        "The method `train` receives the data, and use it for training the tagger.   \n",
        "In this case, it should learn a simple dictionary that **maps words to tags**, defined as the most frequent tag for every word (in case there is more than one most frequent tag, you may select one of them randomly). The dictionary should be stored as a class member for evaluation.\n",
        "\n",
        "The method `evaluate` receives the data, and use it to evaluate the tagger performance. Specifically, you should calculate the word and sentence level accuracy.\n",
        "The evaluation process is simply going word by word, querying the dictionary (created by the train method) for each word’s tag and compare it to the true tag of that word.\n",
        " - The word-level accuracy is the number of successes divided by the number of words. For OOV (out of vocabulary, or unknown) words, the tagger should assign the most frequent tag in the entire training set (i.e., the mode).\n",
        " - Calculate the sentence-level accuracy by dividing the number of correctly predicted sentences by the total number of sentences in the dataset.\n",
        "\n",
        "The function should return the two numbers: word level accuracy and sentence level accuracy.\n",
        "\n",
        "<br>\n",
        "\n",
        "Notes:  \n",
        " - We should avoid using loops except when absolutely necessary!\n",
        " - We should use numpy & pandas operations and function. For example, `apply`, `map`, `sum`, `unique`, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MtivZLBH7dXq"
      },
      "outputs": [],
      "source": [
        "class simple_tagger:\n",
        "  def __init__(self) -> None:\n",
        "    # TO DO\n",
        "    self._seperator = '\\w'\n",
        "    self._word2tag = {}\n",
        "    self._OOV = None\n",
        "    self._maxtag = None\n",
        "\n",
        "  def _get_all_tags(self) -> List[str]:\n",
        "    return list(self._word2tag.values())\n",
        "\n",
        "  def train(self, data) -> None:\n",
        "    \"\"\" This method first counts the tags for each word\n",
        "        Then it inserts into _word2tag the highest viewed tag\n",
        "        It handals ties by choosing a random tag\n",
        "        It also finds the highest seen tag overall\n",
        "    \"\"\"\n",
        "\n",
        "    tag_count = {}       # Each unique word holds a dict of tag: #times seen\n",
        "    all_tags_count = {}  # Count of all the tags across all words\n",
        "\n",
        "    for sentence in data:\n",
        "      for word in sentence:\n",
        "        # Update the tag count for the current word\n",
        "        if tag_count.get(word[0]) == None:\n",
        "          tag_count[word[0]] = {word[1] : 1}\n",
        "        elif tag_count[word[0]].get(word[1]) == None:\n",
        "          tag_count[word[0]][word[1]] = 1\n",
        "        else:\n",
        "          tag_count[word[0]][word[1]] += 1\n",
        "\n",
        "        # Update the count of all tags across all words\n",
        "        if all_tags_count.get(word[1]) == None:\n",
        "          all_tags_count[word[1]] = 1\n",
        "        else:\n",
        "          all_tags_count[word[1]] += 1\n",
        "\n",
        "    # Extract the most common tag for each word\n",
        "    for word, tags in tag_count.items():\n",
        "      tag_counts = np.array(list(tags.values()))\n",
        "      max_count = np.max(tag_counts)\n",
        "      max_indices = np.where(tag_counts == max_count)[0]\n",
        "      highest_tag = list(tags.keys())[np.random.choice(max_indices)]\n",
        "      self._word2tag[word] = highest_tag\n",
        "\n",
        "    # Extract the highest count tag across all words\n",
        "    tags_count = np.array(list(all_tags_count.values()))\n",
        "    max_count = np.max(tags_count)\n",
        "    max_indices = np.where(tags_count == max_count)[0]\n",
        "    self._maxtag = list(all_tags_count.keys())[np.random.choice(max_indices)]\n",
        "\n",
        "\n",
        "  def evaluate(self, data) -> tuple[float,float]:\n",
        "    word_count = 0\n",
        "    correct_words = 0\n",
        "    correct_sen = 0\n",
        "    for sentence in data:\n",
        "      temp_correct_words = 0\n",
        "      for word in sentence:\n",
        "        word_count += 1\n",
        "        pred_tag = self._word2tag.get(word[0], self._maxtag)\n",
        "        if word[1] == pred_tag:\n",
        "          temp_correct_words += 1\n",
        "      if temp_correct_words == len(sentence):\n",
        "        correct_sen += 1\n",
        "      correct_words += temp_correct_words\n",
        "\n",
        "    word_acc = correct_words/word_count\n",
        "    sen_acc = correct_sen/data.shape[0]\n",
        "    return (word_acc, sen_acc)\n",
        "\n",
        "  def create_pred(self, data):\n",
        "    \"\"\"\n",
        "    Returns prediction on labled data\n",
        "    \"\"\"\n",
        "    total_predictions = []\n",
        "    for sentence in data:\n",
        "      sentence_predictions = []\n",
        "      for word in sentence:\n",
        "        if self._word2tag.get(word[0]) == None:\n",
        "          pred_tag = self._maxtag\n",
        "        else:\n",
        "          pred_tag = self._word2tag[word[0]]\n",
        "        sentence_predictions.append((word[0], pred_tag))\n",
        "      total_predictions.append(sentence_predictions)\n",
        "    total_pred = np.array(total_predictions, dtype=object)\n",
        "    return total_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrMMHz_7U2NQ"
      },
      "source": [
        "**Train & Evaluate**  \n",
        "Use the class you created to train and evaluate your model.\n",
        "Save & Print the eveluation scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOX0YVMcU1xw",
        "outputId": "6c688c0b-74b9-498f-cb0d-8a62d6c0ccf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Tagger word/sentence accuracy over training data: 0.93450, 0.42326\n",
            "Simple Tagger word/sentence accuracy over dev data: 0.88434, 0.28380\n",
            "Simple Tagger word/sentence accuracy over test data: 0.86624, 0.21168 \n",
            "\n",
            "       Word_lvl_simple_tagger  sent_lvl_simple_tagger\n",
            "train                0.934496                0.423257\n",
            "dev                  0.884342                0.283796\n",
            "test                 0.866244                0.211679\n"
          ]
        }
      ],
      "source": [
        "simple_t = simple_tagger()\n",
        "simple_t.train(train_data)\n",
        "train_acc = simple_t.evaluate(train_data)\n",
        "dev_acc = simple_t.evaluate(dev_data)\n",
        "test_acc = simple_t.evaluate(test_data)\n",
        "\n",
        "file_name = '{312332372_1}_{209795624_2}_part2.csv'\n",
        "df_simple_t = pd.DataFrame([[train_acc[0], train_acc[1]], [dev_acc[0], dev_acc[1]], [test_acc[0], test_acc[1]]], columns = ['Word_lvl_simple_tagger', 'sent_lvl_simple_tagger'],\n",
        "                  index=['train','dev', 'test'])\n",
        "df_simple_t.to_csv(file_name)\n",
        "\n",
        "print(f\"Simple Tagger word/sentence accuracy over training data: {train_acc[0]:.5f}, {train_acc[1]:.5f}\")\n",
        "print(f\"Simple Tagger word/sentence accuracy over dev data: {dev_acc[0]:.5f}, {dev_acc[1]:.5f}\")\n",
        "print(f\"Simple Tagger word/sentence accuracy over test data: {test_acc[0]:.5f}, {test_acc[1]:.5f} \\n\")\n",
        "print(df_simple_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etK9iZIq8i0X"
      },
      "source": [
        "## Part 3 - Hidden Markov Model (HMM) Tagger\n",
        "\n",
        "Similar to part 2, we will write the class `hmm_tagger`, which implements HMM tagging.\n",
        "\n",
        "The method `train` should build the matrices A, B and Pi, from the data as discussed in class.   \n",
        "The method `evaluate` should find the best tag sequence for every input sentence using he Viterbi decoding algorithm, and then calculate the word and sentence level accuracy using the gold-standard tags.\n",
        "\n",
        "**Notice:** We will implement the Viterbi algorithm in the next block and call it from your class.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Additional Notes:**\n",
        "1. The matrix B represents the emissions probabilities. Since B is a matrix, you should build a dictionary that maps every unique word in the corpus to a serial numeric id (starting with 0). This way columns in B represents word ids.\n",
        "2. During the evaluation, one should first convert each word into it’s index and then create the observation array to be given to Viterbi, as a list of ids. OOV words should be assigned with a random tag. To make sure Viterbi works appropriately, you can simply break the sentence into multiple segments every time you see an OOV word, and decode every segment individually using Viterbi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TpH7GuiQ9L6W"
      },
      "outputs": [],
      "source": [
        "class hmm_tagger:\n",
        "  def __init__(self):\n",
        "\n",
        "    self._Pi = None\n",
        "    self._A = None\n",
        "    self._B = None\n",
        "    self.words_dict = {'UNK' : 0}\n",
        "    self.tags_dict = {}\n",
        "\n",
        "  def train(self, data) -> None:\n",
        "    # Build the transition matrix A\n",
        "    # Initialize the transition matrix A according to the unique tags values\n",
        "    # Initialize the words and tags dictionaries:\n",
        "\n",
        "    tag_id = 0\n",
        "    word_id = 1\n",
        "    for sentence in data:\n",
        "      for word in sentence:\n",
        "        if word[1] not in self.tags_dict:\n",
        "          self.tags_dict[word[1]] = tag_id\n",
        "          tag_id += 1\n",
        "        if word[0] not in self.words_dict:\n",
        "          self.words_dict[word[0]] = word_id\n",
        "          word_id += 1\n",
        "\n",
        "    self._A = np.zeros((len(self.tags_dict),len(self.tags_dict)))\n",
        "\n",
        "    # Counting number of appearances of each transition\n",
        "    for sentence in data:\n",
        "      for idx, word in enumerate(sentence):\n",
        "        if idx == 0:\n",
        "          prev_word_tag = word[1]\n",
        "        if idx != 0:\n",
        "          self._A[self.tags_dict[prev_word_tag]][self.tags_dict[word[1]]] += 1\n",
        "          prev_word_tag = word[1]\n",
        "\n",
        "   # Calculating probabilities of transition matrix\n",
        "    for i in range(self._A.shape[0]):\n",
        "      self._A[i,:] /= np.sum(self._A[i,:])\n",
        "\n",
        "   # Initialize the B and Pi with zeros\n",
        "    self._B = np.zeros((len(self.tags_dict),len(self.words_dict)))\n",
        "    self._Pi = np.zeros((len(self.tags_dict)))\n",
        "\n",
        "   # Calculating emission and initial state matrices\n",
        "    for sentence in data:\n",
        "      for idx,word in enumerate(sentence):\n",
        "        self._B[self.tags_dict[word[1]],self.words_dict[word[0]]] += 1\n",
        "        if idx == 0:\n",
        "          self._Pi[self.tags_dict[word[1]]] += 1\n",
        "\n",
        "  # Calculating probabilities of emission and initial state matrices\n",
        "    total_tags_count = np.sum(self._Pi)\n",
        "    for i in range(self._B.shape[0]):\n",
        "      self._B[i] /= np.sum(self._B[i,:])\n",
        "      self._Pi[i] /= total_tags_count\n",
        "\n",
        "  def flatten(self, l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "  def break_sen(self, sentence):\n",
        "\n",
        "    # Get a sentence and break it into segments according to OOV words\n",
        "    # Return list of lists of segments containing word id's and list of the observed tags\n",
        "\n",
        "    result = []\n",
        "    segment = []\n",
        "    obs_tags_sen = []\n",
        "    for word in sentence:\n",
        "      if word[0] in self.words_dict:\n",
        "        word_id = self.words_dict[word[0]]\n",
        "        segment.append(word_id)\n",
        "        obs_tags_sen.append(self.tags_dict[word[1]])\n",
        "      else:        # OOV case\n",
        "        if len(segment) > 0:\n",
        "          result.append(segment)\n",
        "        word_id = 0\n",
        "        segment = [word_id]\n",
        "        result.append(segment)\n",
        "        segment = []\n",
        "        random_tag = np.random.choice(np.arange(len(self._Pi)), size=1)[0]\n",
        "        obs_tags_sen.append(random_tag)\n",
        "    if segment != []:\n",
        "      result.append(segment)\n",
        "    result_len = 0\n",
        "\n",
        "    return result , obs_tags_sen\n",
        "\n",
        "  def evaluate(self, data) -> tuple[float,float]:\n",
        "\n",
        "    # Converting words into IDs from the evaluated data:\n",
        "    word_count = 0\n",
        "    correct_words = 0\n",
        "    correct_sen = 0\n",
        "    obs_words_data = []\n",
        "    pred_tags_data = []\n",
        "    for sentence in data:\n",
        "      broken_sen,  obs_tags_seq = self.break_sen(sentence)\n",
        "      pred_tags_seq = []\n",
        "      obs_word_sen = self.flatten(broken_sen)\n",
        "      word_count += len(obs_word_sen)\n",
        "      for segment in broken_sen:\n",
        "        if len(segment) <= 1:\n",
        "          random_tag = np.random.choice(np.arange(len(self._Pi)), size =1)[0]\n",
        "          pred_tags_seq = pred_tags_seq + [random_tag]\n",
        "        else:\n",
        "          pred_seg = viterbi(segment, self._A, self._B, self._Pi)\n",
        "          pred_tags_seq = pred_tags_seq + pred_seg\n",
        "      obs_words_data.append(obs_word_sen)\n",
        "      pred_tags_data.append(pred_tags_seq)\n",
        "\n",
        "      if obs_tags_seq == pred_tags_seq:\n",
        "        correct_sen += 1\n",
        "      correct_words += np.sum(np.array(obs_tags_seq) == np.array(pred_tags_seq))\n",
        "    word_acc = correct_words/word_count\n",
        "    sen_acc = correct_sen/data.shape[0]\n",
        "\n",
        "    return (word_acc, sen_acc)\n",
        "\n",
        "  def create_pred(self, data):\n",
        "    \"\"\"\n",
        "    Returns predicted tags on labled data\n",
        "    \"\"\"\n",
        "    total_predictions = []\n",
        "    for sentence in data:\n",
        "      sentence_predictions = []\n",
        "      obs_sentence = []\n",
        "      broken_sen,  obs_tags_seq = self.break_sen(sentence)\n",
        "      pred_tags_seq = []\n",
        "      obs_word_sen = self.flatten(broken_sen)\n",
        "      words = [list(self.words_dict.keys())[list(self.words_dict.values()).index(word_id)] for word_id in obs_word_sen]\n",
        "      for segment in broken_sen:\n",
        "        if len(segment) <= 1:\n",
        "          pred_tags_seq = pred_tags_seq + [np.argmax(self._Pi)]\n",
        "        else:\n",
        "          pred_seg = viterbi(segment, self._A, self._B, self._Pi)\n",
        "          pred_tags_seq = pred_tags_seq + pred_seg\n",
        "      for i,tag in enumerate(pred_tags_seq):\n",
        "        sentence_predictions.append((words[i], list(self.tags_dict.keys())[list(self.tags_dict.values()).index(tag)]))\n",
        "      total_predictions.append(sentence_predictions)\n",
        "    total_pred = np.array(total_predictions, dtype=object)\n",
        "    return total_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni-3uwVmXiKB"
      },
      "source": [
        "**Viterbi Algorithm**\n",
        "\n",
        "Here we implement the `viterbi` function.\n",
        "\n",
        "Also we will run an example to test the Viterbi algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xeamEX8hNCBe"
      },
      "outputs": [],
      "source": [
        "def viterbi(observations, A, B, Pi):\n",
        "  # Number of hidden states\n",
        "  N = len(A)\n",
        "\n",
        "  # Length of observations\n",
        "  T = len(observations)\n",
        "\n",
        "  # Initialize the Viterbi trellis\n",
        "  V = np.empty((N,T))\n",
        "  path = np.empty((N,T))\n",
        "\n",
        "  # Initialize the first column of Viterbi trellis\n",
        "  for state in range(N):\n",
        "    # Initial probability for each state\n",
        "    V[state,0] = Pi[state] * B[state][observations[0]]\n",
        "    path[state,0] = state\n",
        "\n",
        "  # Forward algorithm\n",
        "  for t in range(1, T):\n",
        "    for state in range(N):\n",
        "    # Compute the maximum probability and corresponding previous state\n",
        "      cur_prob = 0\n",
        "      best_prob = 0\n",
        "      best_J = 0\n",
        "      for j in range(N):\n",
        "        cur_prob = V[j,t-1]*A[j,state]\n",
        "        if cur_prob > best_prob:\n",
        "          best_prob = cur_prob\n",
        "          best_J = j\n",
        "\n",
        "      V[state,t] = B[state, observations[t]] * best_prob\n",
        "      path[state,t] = best_J\n",
        "\n",
        "  result = [None for _ in range(T)]\n",
        "  result[T-1] = int(np.argmax(V,axis =0)[T-1])\n",
        "\n",
        "  for t in reversed(range(T-1)):\n",
        "    result[t] = path[int(result[t+1]),t+1]\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bkj25vm2knij"
      },
      "outputs": [],
      "source": [
        "A = np.array([[0.3, 0.7], [0.2, 0.8]])\n",
        "B = np.array([[0.1, 0.1, 0.3, 0.5], [0.3, 0.3, 0.2, 0.2]])\n",
        "Pi = np.array([0.4, 0.6])\n",
        "\n",
        "assert viterbi([0, 3, 2, 0], A, B, Pi) == [1,1,1,1] # Expected output: 1, 1, 1, 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnKUWMhyUgXy"
      },
      "source": [
        "**Train & Evaluate**  \n",
        "We use the class created to train and evaluate the model.\n",
        "Then we will Save & Print the eveluation scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_pNTZcRQUfxe"
      },
      "outputs": [],
      "source": [
        "HMM = hmm_tagger()\n",
        "HMM.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xesl7V9jtMa2",
        "outputId": "f295dee8-c292-4569-ec00-c9ff4db23851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMM accuracy results:\n",
            "      Word_lvl_HMM  sent_lvl_HMM\n",
            "dev       0.857894      0.238138\n",
            "test      0.833028      0.186131\n"
          ]
        }
      ],
      "source": [
        "hmm_dev_acc = HMM.evaluate(dev_data)\n",
        "hmm_test_acc = HMM.evaluate(test_data)\n",
        "\n",
        "file_name = '{312332372_1}_{209795624_2}_part3.csv'\n",
        "df_HMM = pd.DataFrame([[hmm_dev_acc[0], hmm_dev_acc[1]], [hmm_test_acc[0], hmm_test_acc[1]]], columns = ['Word_lvl_HMM', 'sent_lvl_HMM'],\n",
        "                  index=['dev','test'])\n",
        "df_HMM.to_csv(file_name)\n",
        "\n",
        "print(\"HMM accuracy results:\")\n",
        "print(df_HMM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YZO0uGL-4S-"
      },
      "source": [
        "## Part 4 - NLTK Tagger\n",
        "\n",
        "We will compare the results obtained from both taggers and a MEMM (Maximum-entropy Markov model) tagger, implemented by `NLTK` (a known NLP library), over both datasets - dev & test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3ZUAonUlmOgZ"
      },
      "outputs": [],
      "source": [
        "# Data Preparation# Data has been prepared in a way that does'nt need any more preproccessing\n",
        "# will take some time\n",
        "tnt_pos_tagger = tnt.TnT()\n",
        "tnt_pos_tagger.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TjIPZ4AuCsqE"
      },
      "outputs": [],
      "source": [
        "def tnt_acc(data):\n",
        "  \"\"\"\n",
        "  This method calculates words/sentence accuracy over the TnT MEMM tagger\n",
        "  It takes data structured as a list of lists holding tuple of (word, tag)\n",
        "  Returns tuple of (words, sentence) accuracy of predicted tags\n",
        "  \"\"\"\n",
        "  correct_sentences = 0\n",
        "  correct_words = 0\n",
        "  total_words = 0\n",
        "\n",
        "  for sentence in data:\n",
        "    words = [word for word, _ in sentence]     # Extract the words from the sentence\n",
        "    pred = tnt_pos_tagger.tag(words)\n",
        "    correct_words += sum([1 for i in range(len(sentence)) if pred[i] == sentence[i]])\n",
        "    if pred == sentence:\n",
        "        correct_sentences += 1\n",
        "    total_words += len(words)\n",
        "\n",
        "  word_acc = correct_words/total_words\n",
        "  sen_acc = correct_sentences/data.shape[0]\n",
        "  return (word_acc, sen_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ8YwpiyvJ6l"
      },
      "source": [
        "Evaluating the `NLTK` tagger on the train & test datasets.  \n",
        "Save & Print the eveluation scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UW9qPE19NKHz"
      },
      "outputs": [],
      "source": [
        "dev_acc = tnt_acc(dev_data)\n",
        "test_acc = tnt_acc(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYhtboJm_Iyx",
        "outputId": "3c011468-cd1e-4be2-c17b-5466a9a4bc33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEMM Tagger dev word accuracy: 0.87728\n",
            "MEMM Tagger test word accuracy: 0.85583\n",
            "MEMM Tagger dev sentence accuracy: 0.26768\n",
            "MEMM Tagger test sentence accuracy: 0.20620 \n",
            "\n",
            "      Word_lvl_MEMM  sent_lvl_MEMM\n",
            "dev        0.877279       0.267681\n",
            "test       0.855833       0.206204\n"
          ]
        }
      ],
      "source": [
        "file_name = '{312332372_1}_{209795624_2}_part4.csv'\n",
        "df_tnt_t = pd.DataFrame([[dev_acc[0], dev_acc[1]], [test_acc[0], test_acc[1]]], columns = ['Word_lvl_MEMM', 'sent_lvl_MEMM'],\n",
        "                  index=['dev','test'])\n",
        "df_tnt_t.to_csv(file_name)\n",
        "\n",
        "print(f\"MEMM Tagger dev word accuracy: {dev_acc[0]:.5f}\")\n",
        "print(f\"MEMM Tagger test word accuracy: {test_acc[0]:.5f}\")\n",
        "print(f\"MEMM Tagger dev sentence accuracy: {dev_acc[1]:.5f}\")\n",
        "print(f\"MEMM Tagger test sentence accuracy: {test_acc[1]:.5f} \\n\")\n",
        "print(df_tnt_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQfnJ0DaUWms"
      },
      "source": [
        "# Part 5 - Improved Tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DIvvzsq_U-o"
      },
      "source": [
        "Now we will calculate both word level and sentence level accuracy for all the three taggers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCYOP60JUb6x",
        "outputId": "8b6373cc-7926-4d0c-dd9f-d9711ecb7f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+-----------------+--------------------------+--------------------------+----------------+----------------+\n",
            "|      |   Word_lvl_MEMM |   sent_lvl_MEMM |   Word_lvl_simple_tagger |   sent_lvl_simple_tagger |   Word_lvl_HMM |   sent_lvl_HMM |\n",
            "|------+-----------------+-----------------+--------------------------+--------------------------+----------------+----------------|\n",
            "| dev  |        0.877279 |        0.267681 |                 0.884342 |                 0.283796 |       0.857894 |       0.238138 |\n",
            "| test |        0.855833 |        0.206204 |                 0.866244 |                 0.211679 |       0.833028 |       0.186131 |\n",
            "+------+-----------------+-----------------+--------------------------+--------------------------+----------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "df_combined = pd.concat([df_tnt_t, df_simple_t.iloc[1:,:], df_HMM] , axis=1)\n",
        "file_name = '{312332372_1}_{209795624_2}_part5.csv'\n",
        "df_combined.to_csv(file_name)\n",
        "print(tabulate(df_combined, headers='keys', tablefmt='psql'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llyv7-Trlav0"
      },
      "source": [
        "**Improved Tagger**  \n",
        "\n",
        "Base on our general knowlege in the filed of ML, and what we learned in the NLP course so far;  \n",
        "We will atempt to create our own tagger, and **make sure to improve the scores on the test dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed a short EDA and noticed that around 10% of test data has OOV words.\n",
        "Our assumption is that creating a more generalized model will improve performance.  We tried 3 approaches:\n",
        "  1. Creating an ensemble of the 3 models, the prediction is the majority vote.\n",
        "  2. Use Word2Vec and a linear classifier for tag predictions, the underlying assumption here is that OOV words will be handled better when mapping to latent space.\n",
        "  3. Improving the HMM model by using Laplace smoothing over transition matrix and handling OOV cases with training data statistics (most common tag).\n",
        "\n",
        "We found that the 3'rd option yeilded the best results."
      ],
      "metadata": {
        "id": "fQmoJA3q1Vwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class improved_tagger:\n",
        "  def __init__(self):\n",
        "    # TO DO\n",
        "    self._Pi = None\n",
        "    self._A = None\n",
        "    self._B = None\n",
        "\n",
        "    self.words_dict = {'UNK' : 0}\n",
        "    self.tags_dict = {}\n",
        "\n",
        "\n",
        "  def train(self, data) -> None:\n",
        "    # Build the transition matrix A\n",
        "    # Initialize the transition matrix A according to the unique tags values\n",
        "    # Initialize the words and tags dictionaries:\n",
        "\n",
        "    tag_id = 0\n",
        "    word_id = 1\n",
        "    for sentence in data:\n",
        "      for word in sentence:\n",
        "        if word[1] not in self.tags_dict:\n",
        "          self.tags_dict[word[1]] = tag_id\n",
        "          tag_id += 1\n",
        "        if word[0] not in self.words_dict:\n",
        "          self.words_dict[word[0]] = word_id\n",
        "          word_id += 1\n",
        "\n",
        "    self._A = np.zeros((len(self.tags_dict),len(self.tags_dict)))\n",
        "\n",
        "    # Counting number of appearances of each transition\n",
        "    for sentence in data:\n",
        "      for idx, word in enumerate(sentence):\n",
        "        if idx == 0:\n",
        "          prev_word_tag = word[1]\n",
        "        if idx != 0:\n",
        "          self._A[self.tags_dict[prev_word_tag]][self.tags_dict[word[1]]] += 1\n",
        "          prev_word_tag = word[1]\n",
        "\n",
        "   # Calculating probabilities of transition matrix with laplace smoothing\n",
        "    K = len(self.tags_dict)\n",
        "    for i in range(self._A.shape[0]):\n",
        "      N = np.sum(self._A[i,:])\n",
        "      self._A[i,:] += 1\n",
        "      self._A[i,:] /= (N + K)\n",
        "\n",
        "\n",
        "   # Initialize the B and Pi with zeros\n",
        "\n",
        "    self._B = np.zeros((len(self.tags_dict),len(self.words_dict)))\n",
        "    self._Pi = np.zeros((len(self.tags_dict)))\n",
        "\n",
        "   # Calculating emission and state matrices\n",
        "    for sentence in data:\n",
        "      for word in sentence:\n",
        "        self._B[self.tags_dict[word[1]],self.words_dict[word[0]]] += 1\n",
        "        self._Pi[self.tags_dict[word[1]]] += 1    # Note that here we created a global prior tag state\n",
        "\n",
        "\n",
        "  # Calculating probabilities of emission and state matrices\n",
        "    total_tags_count = np.sum(self._Pi)\n",
        "    for i in range(self._B.shape[0]):\n",
        "      self._B[i] /= np.sum(self._B[i,:])\n",
        "      self._Pi[i] /= total_tags_count\n",
        "\n",
        "  def flatten(self, l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "  def break_sen(self, sentence):\n",
        "\n",
        "    # Get a sentence and break it into segments according to OOV words\n",
        "    # Return list of lists of segments and obs_tags_sen.\n",
        "    # Notice that if the function return a list with only one item (list) that means there were no OOV words\n",
        "\n",
        "    result = []\n",
        "    segment = []\n",
        "    obs_tags_sen = []\n",
        "    for word in sentence:\n",
        "      if word[0] in self.words_dict:\n",
        "        word_id = self.words_dict[word[0]]\n",
        "        segment.append(word_id)\n",
        "        obs_tags_sen.append(self.tags_dict[word[1]])\n",
        "      else:        # OOV case\n",
        "        if len(segment) > 0:\n",
        "          result.append(segment)\n",
        "        word_id = 0\n",
        "        segment = [word_id]\n",
        "        result.append(segment)\n",
        "        segment = []\n",
        "        max_tag_pi = np.argmax(self._Pi)\n",
        "        obs_tags_sen.append(max_tag_pi)\n",
        "    if segment != []:\n",
        "      result.append(segment)\n",
        "    result_len = 0\n",
        "\n",
        "    return result , obs_tags_sen\n",
        "\n",
        "\n",
        "  def evaluate(self, data) -> tuple[float,float]:\n",
        "\n",
        "    # Converting words into IDs from the evaluated data:\n",
        "    word_count = 0\n",
        "    correct_words = 0\n",
        "    correct_sen = 0\n",
        "    obs_words_data = []\n",
        "    pred_tags_data = []\n",
        "    for sentence in data:\n",
        "      broken_sen,  obs_tags_seq = self.break_sen(sentence)\n",
        "      pred_tags_seq = []\n",
        "      obs_word_sen = self.flatten(broken_sen)\n",
        "      word_count += len(obs_word_sen)\n",
        "      for segment in broken_sen:\n",
        "        if len(segment) <= 1:\n",
        "          pred_tags_seq = pred_tags_seq + [np.argmax(self._Pi)]\n",
        "        else:\n",
        "          pred_seg = viterbi(segment, self._A, self._B, self._Pi)\n",
        "          pred_tags_seq = pred_tags_seq + pred_seg\n",
        "      obs_words_data.append(obs_word_sen)\n",
        "      pred_tags_data.append(pred_tags_seq)\n",
        "\n",
        "\n",
        "      if obs_tags_seq == pred_tags_seq:\n",
        "        correct_sen += 1\n",
        "      correct_words += np.sum(np.array(obs_tags_seq) == np.array(pred_tags_seq))\n",
        "    word_acc = correct_words/word_count\n",
        "    sen_acc = correct_sen/data.shape[0]\n",
        "\n",
        "    return (word_acc, sen_acc)\n",
        "\n",
        "  def create_pred(self, data):\n",
        "    \"\"\"\n",
        "    Returns predicted tags on labled data\n",
        "    \"\"\"\n",
        "    total_predictions = []\n",
        "    for sentence in data:\n",
        "      sentence_predictions = []\n",
        "      obs_sentence = []\n",
        "\n",
        "      broken_sen,  obs_tags_seq = self.break_sen(sentence)\n",
        "      pred_tags_seq = []\n",
        "      obs_word_sen = self.flatten(broken_sen)\n",
        "      words = [list(self.words_dict.keys())[list(self.words_dict.values()).index(word_id)] for word_id in obs_word_sen]\n",
        "      for segment in broken_sen:\n",
        "        if len(segment) <= 1:\n",
        "          pred_tags_seq = pred_tags_seq + [np.argmax(self._Pi)]\n",
        "        else:\n",
        "          pred_seg = viterbi(segment, self._A, self._B, self._Pi)\n",
        "          pred_tags_seq = pred_tags_seq + pred_seg\n",
        "      for i,tag in enumerate(pred_tags_seq):\n",
        "        sentence_predictions.append((words[i], list(self.tags_dict.keys())[list(self.tags_dict.values()).index(tag)]))\n",
        "      total_predictions.append(sentence_predictions)\n",
        "    total_pred = np.array(total_predictions, dtype=object)\n",
        "    return total_pred"
      ],
      "metadata": {
        "id": "Cdwk4OOcMQJ0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWO9E2AbV0MZ"
      },
      "source": [
        "**Train & Evaluate**  \n",
        "Now we will use the class we created to train and evaluate the model.\n",
        "Save & Print the eveluation scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kA6l6zL6V0X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78802770-ed18-4df9-b77b-0e9c98aa430d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test word accuracy: 0.9293540231024738\n",
            "Test sentence accuracy: 0.36405109489051096\n"
          ]
        }
      ],
      "source": [
        "improved_t = improved_tagger()\n",
        "improved_t.train(train_data)\n",
        "improved_word_acc_test, improved_sen_acc_test = improved_t.evaluate(test_data)\n",
        "improved_word_acc_dev, improved_sen_acc_dev = improved_t.evaluate(dev_data)\n",
        "print(f\"Test word accuracy: {improved_word_acc_test}\")\n",
        "print(f\"Test sentence accuracy: {improved_sen_acc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d91lm1TTV5Ch"
      },
      "source": [
        "## Part 6 - Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DbQYcK2mWiMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2750efce-0da5-4f02-cc6f-de2e9ad87003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+-----------------+--------------------------+--------------------------+----------------+----------------+---------------------+---------------------+\n",
            "|      |   Word_lvl_MEMM |   sent_lvl_MEMM |   Word_lvl_simple_tagger |   sent_lvl_simple_tagger |   Word_lvl_HMM |   sent_lvl_HMM |   word_lvl_IMPROVED |   sent_lvl_IMPROVED |\n",
            "|------+-----------------+-----------------+--------------------------+--------------------------+----------------+----------------+---------------------+---------------------|\n",
            "| dev  |        0.877279 |        0.267681 |                 0.884342 |                 0.283796 |       0.857894 |       0.238138 |            0.934182 |            0.376007 |\n",
            "| test |        0.855833 |        0.206204 |                 0.866244 |                 0.211679 |       0.833028 |       0.186131 |            0.929354 |            0.364051 |\n",
            "+------+-----------------+-----------------+--------------------------+--------------------------+----------------+----------------+---------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "df_improved= pd.DataFrame([[improved_word_acc_dev, improved_sen_acc_dev], [improved_word_acc_test, improved_sen_acc_test]], columns = ['word_lvl_IMPROVED', 'sent_lvl_IMPROVED'],\n",
        "                  index=['dev','test'])\n",
        "df_results = pd.concat([df_combined, df_improved] , axis=1)\n",
        "print(tabulate(df_results, headers='keys', tablefmt='psql'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "O4CEiR6uWbNb"
      },
      "outputs": [],
      "source": [
        "file_name = 'part6.csv'\n",
        "df_results.to_csv(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJM2kXzDWvNe"
      },
      "source": [
        "<br><br><br>\n",
        "Good Luck."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
